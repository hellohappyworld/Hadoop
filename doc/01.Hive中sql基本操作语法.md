#### HIVE基本操作

##### 1.数据库的创建与删除

本质上是在hdfs上创建一个目录

```
##创建一个数据库名为myhive,加入描述信息及属性信息
hive> create database myhive comment 'this is myhive db'
    > with dbproperties('author'='me','date'='2018-5-10');
##查看属性信息
hive> describe database extended myhive;
OK
myhive	this is myhive db	hdfs://min1:9000/user/hive/warehouse/myhive.db	hadoop	USER	{author=me, date=2018-5-10}
##在原有数据库基础上加入新的属性信息
hive> alter database myhive set dbproperties ('id'='1');
OK
Time taken: 0.108 seconds
hive> describe database extended myhive;
OK
myhive	this is myhive db	hdfs://min1:9000/user/hive/warehouse/myhive.db	hadoop	USER	{id=1, author=me, date=2018-5-10}
##切换库
hive> use myhive;
##删除具有表的数据库
hive> drop database school cascade;
##删除空数据库
hive> drop database school;
```



##### 2.表的创建

默认创建到当前数据库(default是hive默认库)，创建表的本质也是在hdfs上创建一个目录

- 联系array的使用

```
1.创建数据array.txt映射表t_array
hive> create table t_array
    > (id int,grade array<int>)
    > row format delimited
    > fields terminated by ' '
    > collection items terminated by ','
    > ;
2.从本地加载数据array.txt文件
[hadoop@min1 testData]$ cat array.txt
01 11,22,33,44,55
02 12,13,14
03 14,15,16 
04 22,23,24,25
将本地（linux）中的文件上传到hive中，关键字为local;将hdfs中文件上传#到hive中，不使用local关键字
hive> load data local inpath '/home/hadoop/testData/aa.txt'
    > into table t_array;
3.查询表里面的数据
hive> select * from t_array;
OK
1	[11,22,33,44,55]
2	[12,13,14]
3	[14,15,16]
4	[22,23,24,25]
4.查询表属性
hive> desc t_array;
OK
id                  	int                 	             
grade               	array<int>  
5.查询id=1的第一条成绩信息
hive> select grade[0] from t_array where id=1;
hive> select size(grade) from t_array where id=2;
OK
3
6.查询id=2的成绩条数
hive> select size(grade) from t_array where id=2;
OK
3
7.查询一共有多少条数据
hive> select count(*) from t_array;
8.把arra1.txt追加的方式从本地加载进这个表中
hive> load data local inpath '/home/hadoop/testData/array1.txt' 
    > into table t_array;
表对应文件夹结构：/user/hive/warehouse/myhive.db/t_array目录下：
-rwxr-xr-x	hadoop	supergroup	58 B	2018/5/11 下午5:09:05	2	128 MB	array.txt
-rwxr-xr-x	hadoop	supergroup	51 B	2018/5/11 下午5:20:40	2	128 MB	array1.txt
查询追加数据后的表：
hive> select * from t_array;
OK
1	[11,22,33,44,55]
2	[12,13,14]
3	[14,15,16]
4	[22,23,24,25]
1	[12,23,11,34]
2	[12,1]
3	[98]
4	[12,23,54,2,6,12,67]
9.从本地覆盖方式加载数据array.txt文件至t_array表中（关键字overwrite）
hive> load data local inpath '/home/hadoop/testData/array.txt'
    > overwrite into table t_array;
覆盖后表对应文件夹结构：/user/hive/warehouse/myhive.db/t_array
-rwxr-xr-x	hadoop	supergroup	58 B	2018/5/11 下午5:28:41	2	128 MB	array.txt

```

- 练习map的使用

  ```
  1.创建数据map.txt的映射表t_map
  hive> create table t_map
      > (id int,score map<string,int>)
      > row format delimited
      > fields terminated by ','
      > collection items terminated by '|'
      > map keys terminated by ':'
      > stored as textfile
      > ;
  表结构：
  hive> desc t_map;
  OK
  id                  	int                 	     
  score               	map<string,int>  
  2.将map.txt上传到hive中
  hive> load data local inpath '/home/hadoop/testData/map.txt'
      > into table t_map;
  map.txt文件结构
  [hadoop@min1 testData]$ cat map.txt
  01,chinese:90|math:89|english:78
  02,chinese:90|math:89|english:78
  03,chinese:90|math:89|english:78
  04,chinese:90|math:89|english:78
  05,chinese:90|math:89|english:78

  3.查询表；查询id=1的数学成绩
  hive> select * from t_map;
  OK
  1	{"chinese":90,"math":89,"english":78}
  2	{"chinese":90,"math":89,"english":78}
  3	{"chinese":90,"math":89,"english":78}
  4	{"chinese":90,"math":89,"english":78}
  5	{"chinese":90,"math":89,"english":78}

  hive> select score['math'] from t_map where id=1;
  OK
  89

  4.查询每个人考了多少科
  hive> select size(score) from t_map;
  OK
  3
  3
  3
  3
  3

  5.查看表的创建过程
  hive> show create table t_map;
  OK
  CREATE TABLE `t_map`(
    `id` int, 
    `score` map<string,int>)
    ROW FORMAT DELIMITED 
    FIELDS TERMINATED BY ',' 
    COLLECTION ITEMS TERMINATED BY '|' 
    MAP KEYS TERMINATED BY ':' ）
  6.创建表的同时指定数据的位置
  hive> create table t_map2
      > (id int,score map<string,int>)
      > row format delimited
      > fields terminated by ','
      > collection items terminated by '|'
      > map keys terminated by ':'
      > stored as textfile
      > location '/map'	#hdfs中的文件
      > ;
  注意：该t_map2表并没有在hdfs集群里创建相应的文件结构，但是能使用sql语句使其显示或显示其内容
  hive> show tables;
  OK
  t_array
  t_map
  t_map2

  hive> select * from t_map2;
  OK
  1	{"chinese":90,"math":89,"english":78}
  2	{"chinese":90,"math":89,"english":78}
  3	{"chinese":90,"math":89,"english":78}
  4	{"chinese":90,"math":89,"english":78}
  5	{"chinese":90,"math":89,"english":78}

  7.删除表
  hive> drop table t_map2;
  OK
  Time taken: 1.6 seconds
  hive> show tables;
  OK
  t_array
  t_map
  ```

  ​

- 练习struct的使用

  ```
  1.创建数据struct.txt的映射表t_struct
  hive> create table t_struct
      > (id int,grade struct<chinese:int,math:int,english:int>)
      > row format delimited
      > fields terminated by ','
      > collection items terminated by '|'
      > ;
  注意：struct.txt文件结构：
  [hadoop@min1 testData]$ cat struct.txt
  01,90|89|78
  02,90|89|78
  03,90|89|78
  04,90|89|78
  05,90|89|78

  2.查看表
  hive> select * from t_struct;
  OK
  1	{"chinese":90,"math":89,"english":78}
  2	{"chinese":90,"math":89,"english":78}
  3	{"chinese":90,"math":89,"english":78}
  4	{"chinese":90,"math":89,"english":78}
  5	{"chinese":90,"math":89,"english":78}

  3.查看math>70的信息
  hive> select * from t_struct where grade.math>70;
  OK
  1	{"chinese":90,"math":89,"english":78}
  2	{"chinese":90,"math":89,"english":78}
  3	{"chinese":90,"math":89,"english":78}
  4	{"chinese":90,"math":89,"english":78}
  5	{"chinese":90,"math":89,"english":78}

  4.insert into 方式追加数据（同样方式先创建表t_struct1）
  hive> insert into table t_struct select *from t_struct1;

  hive> select * from t_struct
      > ;
  OK
  1	{"chinese":90,"math":89,"english":78}
  2	{"chinese":90,"math":89,"english":78}
  3	{"chinese":90,"math":89,"english":78}
  4	{"chinese":90,"math":89,"english":78}
  5	{"chinese":90,"math":89,"english":78}
  1	{"chinese":90,"math":89,"english":78}
  2	{"chinese":90,"math":89,"english":78}
  3	{"chinese":90,"math":89,"english":78}
  4	{"chinese":90,"math":89,"english":78}
  5	{"chinese":90,"math":89,"english":78}
  注意：此时表t_struct对应的文件夹中增加了一个文件：
  -rwxr-xr-x	hadoop	supergroup	55 B	2018/5/11 下午7:13:04	2	128 MB	000000_0
  查询表t_struct对应文件夹中文件；
  -rwxr-xr-x	hadoop	supergroup	55 B	2018/5/11 下午7:13:04	2	128 MB	000000_0
  1,90|89|78
  2,90|89|78
  3,90|89|78
  4,90|89|78
  5,90|89|78
  [hadoop@min1 testData]$ hadoop fs -cat /user/hive/warehouse/myhive.db/t_struct/struct.txt
  01,90|89|78
  02,90|89|78
  03,90|89|78
  04,90|89|78
  05,90|89|78

  ```

  ​

##### 3.为hive表加载数据

将数据文件上传到对应的table目录下（如果是本地（linux系统）的目录，将是拷贝；如果是hdfs的目录，将是剪切）

```
1.load方式从本地(linux系统)加载数据，会将数据拷贝到表对应的hdfs目录中
#追加
load data local inpath '本地数据路径' into table tablename;
#覆盖
load data local inpath '本地数据路径' overwrite into table tablename;
```

```
2.load方式从hdfs加载数据，会将数据移动到对应的hdfs目录中
#追加
load data inpath 'hdfs数据路径' into table tablename;
#覆盖
load data inpath 'hdfs数据路径' overwrite into table tablename;
```

```
3.通过查询语句向表中插入数据
#追加
insert into table table1 select * from table2;
#覆盖
insert overwrite into table table1 select * from table2;
```



##### 4.内部表与外部表

- 内部表：

  在Hive中创建表时，默认情况下Hive负责管理数据。即Hive将数据移入它的数据仓库。

- 外部表：

  由用户来控制数据的创建和删除。外部数据的位置需要在创建表的时候指明。使用external关键字以后，Hive知道数据并不由自己管理，因此不会把数据移入自己的仓库目录。事实上，在定义时它不会检查这一外部位置是否存在。这是一个很重要的特性，也就意味着把创建数据推迟到创建表之后进行

- 区别：

  当丢弃内部表时，这个表（包括它的元数据和数据）会被一起删除。

  当丢弃外部表时，Hive不会碰数据，只会删除元数据，不会删除外部数据文件本身。

##### 5.表属性修改

```
1.创建外部表
hive> create external table log
    > (id int,name string)
    > row format delimited 
    > fields terminated by ' '
    > lines terminated by '\n'
    > stored as textfile;
2.加载数据
hive> load data local inpath '/home/hadoop/testData/a.txt'
    > into table log;
```

- 修改表名

  alter table原名rename to 新名

  ```
  hive> alter table log rename to log2;
  hive> show tables;
  OK
  log2

  hive> alter table log2 rename to log;
  hive> show tables;
  OK
  log
  ```

  ​

- 修改列名

  alter table 表名 change column 字段名 新字段名 字段类型【描述信息】

  ```
  表log原属性信息：
  hive> desc log;
  OK
  id                  	int                
  name                	string     
  1.修改列名
  hive> alter table log change column idhive> desc log;
  hive> desc log;
  OK
  myid                	string              	     
  name                	string myid String;
  2.修改列名同时加入列的描述
  hive> alter table log change column myid ip string 
      > comment 'this is mysip';
  hive> desc log;
  OK
  ip                  	string              	this is mysip       
  name                	string                   
  3.使用after关键字，将修改后的字段放在某个字段后
  hive> alter table log change column ip id int 
      > comment 'this is id'
      > after name;
      
  hive> desc log;
  OK
  name                	string                      
  id                  	int                 	this is id     
  4.使用first关键字。将修改的字段调整到第一个字段
  hive> alter table log change column id myid int first;

  hive> desc log;
  OK
  myid                	int                 	this is id          
  name                	string              	    
  ```

  ​

- 添加列

  ```
  hive> alter table log add columns
      > (grade int comment 'this grade',age int);
      
  hive> desc log;
  OK
  myid                	int                 	this is id          
  name                	string                      
  grade               	int                 	this grade          
  age                 	int                 	           
  ```

  ​

- 删除列

  ```
  hive> alter table log replace columns
      > (myid int,name string);

  hive> desc log;
  OK
  myid                	int                          
  name                	string   
  ```

  ​

- 内部表，外部表转换

  ```
  #表log原为外部表
  hive> alter table log set tblproperties
      > ('external'='false');
  #表t_map原为内部表
  hive> alter table t_map set tblproperties
      > ('external'='true');    
  ```

  ​


